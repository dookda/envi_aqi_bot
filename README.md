# AQI Data Pipeline with LSTM-based Imputation

A complete solution for hourly air quality data collection, storage, and intelligent missing value imputation using LSTM deep learning models.

## ðŸ“‹ Overview

This project implements the specification defined in `lstm_spec.md`:

- **Data Ingestion**: Fetches PM2.5 data from Air4Thai APIs
- **Storage**: PostgreSQL with TimescaleDB for time-series data
- **LSTM Imputation**: Deep learning model for predicting missing values
- **Automated Pipeline**: Scheduled hourly ingestion and imputation
- **Validation**: RMSE/MAE metrics with baseline comparison

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AQI Data Pipeline                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Air4Thai   â”‚â”€â”€â”€â”€â–¶â”‚  Ingestion  â”‚â”€â”€â”€â”€â–¶â”‚ TimescaleDB â”‚        â”‚
â”‚  â”‚    APIs     â”‚     â”‚   Service   â”‚     â”‚  (Storage)  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                  â”‚               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                      â”‚    LSTM     â”‚â—€â”€â”€â”€â”€â”‚  Missing    â”‚        â”‚
â”‚                      â”‚   Model     â”‚     â”‚  Detection  â”‚        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                             â”‚                                    â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                      â”‚ Imputation  â”‚â”€â”€â”€â”€â–¶â”‚ Validation  â”‚        â”‚
â”‚                      â”‚   Service   â”‚     â”‚   Service   â”‚        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local development)

### Running with Docker

1. **Clone and configure**:
   ```bash
   cp .env.example .env
   # Edit .env with your settings
   ```

2. **Start all services**:
   ```bash
   docker-compose up -d
   ```

3. **Access the API**:
   - API: http://localhost:8000
   - Docs: http://localhost:8000/docs

### Local Development

1. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Start PostgreSQL with TimescaleDB**:
   ```bash
   docker-compose up -d timescaledb
   ```

3. **Run the API**:
   ```bash
   uvicorn app.main:app --reload
   ```

4. **Run the scheduler** (in another terminal):
   ```bash
   python -m app.scheduler
   ```

## ðŸ“ Project Structure

```
envi_aqi_bot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ database.py           # Database connection
â”‚   â”œâ”€â”€ logger.py             # Logging configuration
â”‚   â”œâ”€â”€ main.py               # FastAPI application
â”‚   â”œâ”€â”€ models.py             # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ schemas.py            # Pydantic schemas
â”‚   â”œâ”€â”€ scheduler.py          # APScheduler for automation
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ingestion.py      # Data ingestion service
â”‚       â”œâ”€â”€ imputation.py     # LSTM imputation service
â”‚       â”œâ”€â”€ lstm_model.py     # LSTM model training/prediction
â”‚       â””â”€â”€ validation.py     # Model validation service
â”œâ”€â”€ database/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01_init.sql       # Database initialization
â”œâ”€â”€ alembic/                  # Database migrations
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ models/                   # Saved LSTM models (generated)
â”œâ”€â”€ logs/                     # Application logs (generated)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ”§ API Endpoints

### Health & Status
- `GET /health` - Health check
- `GET /` - API info

### Stations
- `GET /api/stations` - List all stations
- `GET /api/stations/{id}` - Get station with stats
- `POST /api/stations/sync` - Sync from Air4Thai

### AQI Data
- `GET /api/aqi/{station_id}` - Get AQI data
- `GET /api/aqi/{station_id}/latest` - Get latest reading
- `GET /api/aqi/{station_id}/missing` - Analyze missing data

### Ingestion
- `POST /api/ingest/batch` - Start batch ingestion
- `POST /api/ingest/hourly` - Trigger hourly update
- `GET /api/ingest/logs` - Get ingestion logs

### Model Training
- `POST /api/model/train` - Train model for station
- `POST /api/model/train-all` - Train all models
- `GET /api/model/{station_id}/info` - Get model info
- `GET /api/model/training-logs` - Get training logs

### Imputation
- `POST /api/impute` - Impute for station
- `POST /api/impute/all` - Impute all stations
- `GET /api/impute/logs` - Get imputation logs
- `POST /api/impute/rollback` - Rollback imputations

### Validation
- `POST /api/validate/{station_id}` - Validate model
- `POST /api/validate/all` - Validate all models

### Pipeline
- `POST /api/pipeline/run` - Run full pipeline

## ðŸ§  LSTM Model Architecture

As specified in `lstm_spec.md`:

```
Input (24 hours) â†’ LSTM(64) â†’ Dropout(0.2) â†’ LSTM(32) â†’ Dropout(0.2) â†’ Dense(1)
```

- **Sequence Length**: 24 hours
- **Loss Function**: Mean Squared Error (MSE)
- **Training**: Only on contiguous sequences (no gaps)

## ðŸ“Š Missing Data Classification

| Gap Type | Duration | Action |
|----------|----------|--------|
| Short | 1-3 hours | Impute |
| Medium | 4-24 hours | Impute |
| Long | >24 hours | Flag only |

## âœ… Validation & Acceptance Criteria

The system validates models against baselines:

1. **LSTM RMSE** < **Linear Interpolation RMSE**
2. No negative PM2.5 predictions

Baselines compared:
- Linear interpolation
- Forward-fill (naive)

## ðŸ”„ Automated Pipeline

The scheduler runs hourly:

1. **Ingest**: Fetch latest data from Air4Thai
2. **Detect**: Identify missing values
3. **Impute**: Fill gaps using LSTM (where applicable)
4. **Commit**: Save to database

Configure schedule in `.env`:
```
INGEST_CRON_HOUR=*
INGEST_CRON_MINUTE=5
```

## ðŸ“ Logging & Auditability

All operations are logged:

- **Imputation events**: Station, datetime, value, model version
- **Training events**: Samples, RMSE, MAE, duration
- **Ingestion events**: Records fetched/inserted, missing detected

Logs are stored in:
- `logs/app.log` - All logs
- `logs/errors.log` - Errors only
- `logs/ingestion.log` - Ingestion events
- `logs/imputation.log` - Imputation events

## ðŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app tests/

# Run specific test file
pytest tests/test_lstm_model.py -v
```

## ðŸ” Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | `postgresql://...` |
| `SEQUENCE_LENGTH` | LSTM input sequence length | `24` |
| `LSTM_UNITS_1` | First LSTM layer units | `64` |
| `LSTM_UNITS_2` | Second LSTM layer units | `32` |
| `EPOCHS` | Max training epochs | `100` |
| `EARLY_STOPPING_PATIENCE` | Early stopping patience | `10` |
| `INGEST_CRON_HOUR` | Cron schedule hour | `*` |
| `INGEST_CRON_MINUTE` | Cron schedule minute | `5` |

## ðŸ“ˆ Future Extensions

As noted in the specification, the system is designed to be extendable to:
- PM10, O3, NO2 parameters
- Multi-station spatial interpolation
- Forecasting capabilities

## ðŸ“„ License

MIT License

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request
