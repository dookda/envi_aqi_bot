/**
 * Custom hook for Claude AI Chat functionality
 * Uses Anthropic Claude API for faster inference compared to Ollama
 */
import { useState, useCallback } from 'react'

// Use BASE_URL from Vite config to ensure /ebot/ prefix is included
const API_URL = import.meta.env.VITE_API_URL || `${import.meta.env.BASE_URL}api`.replace(/\/+/g, '/').replace(/\/$/, '')

export default function useClaude() {
    const [messages, setMessages] = useState([])
    const [loading, setLoading] = useState(false)
    const [error, setError] = useState(null)
    const [lastResponseTime, setLastResponseTime] = useState(null)

    const sendMessage = useCallback(async (query) => {
        if (!query.trim()) return

        // Add user message
        const userMessage = {
            id: Date.now(),
            type: 'user',
            text: query,
            timestamp: new Date().toISOString()
        }
        setMessages(prev => [...prev, userMessage])

        setLoading(true)
        setError(null)

        try {
            const startTime = Date.now()

            const response = await fetch(`${API_URL}/chat/claude/query`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ query })
            })

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`)
            }

            const result = await response.json()
            const clientTime = Date.now() - startTime

            // Use server-reported time if available, otherwise client time
            const responseTimeMs = result.response_time_ms || clientTime
            setLastResponseTime(responseTimeMs)

            // Add bot response
            const botMessage = {
                id: Date.now() + 1,
                type: 'bot',
                text: result.message || getResponseText(result),
                timestamp: new Date().toISOString(),
                data: result.data,
                summary: result.summary,
                intent: result.intent,
                status: result.status,
                output_type: result.output_type,
                llm_provider: result.llm_provider || 'claude',
                response_time_ms: responseTimeMs
            }

            setMessages(prev => [...prev, botMessage])
        } catch (err) {
            console.error('Claude error:', err)
            setError(err.message)

            // Add error message
            const errorMessage = {
                id: Date.now() + 1,
                type: 'bot',
                text: '‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ Claude AI ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ANTHROPIC_API_KEY',
                timestamp: new Date().toISOString(),
                status: 'error',
                llm_provider: 'claude'
            }
            setMessages(prev => [...prev, errorMessage])
        } finally {
            setLoading(false)
        }
    }, [])

    const clearMessages = useCallback(() => {
        setMessages([])
        setError(null)
        setLastResponseTime(null)
    }, [])

    return {
        messages,
        loading,
        error,
        lastResponseTime,
        sendMessage,
        clearMessages
    }
}

function getResponseText(result) {
    if (result.status === 'out_of_scope') {
        return result.message || '‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô'
    }

    if (result.status === 'invalid_request') {
        return result.message || '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà'
    }

    if (result.status === 'error') {
        return result.message || '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á'
    }

    if (result.status === 'success' && result.summary) {
        const s = result.summary
        let text = `üß† Claude AI Response (${result.response_time_ms}ms)\n\n`
        text += `‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5:\n\n`
        text += `‚Ä¢ ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: ${s.mean} Œºg/m¬≥\n`
        text += `‚Ä¢ ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: ${s.max} Œºg/m¬≥\n`
        text += `‚Ä¢ ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î: ${s.min} Œºg/m¬≥\n`
        text += `‚Ä¢ ‡∏à‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ${s.valid_points}/${s.data_points} ‡∏à‡∏∏‡∏î\n`

        if (s.aqi_level) {
            const levels = {
                excellent: '‡∏î‡∏µ‡∏°‡∏≤‡∏Å',
                good: '‡∏î‡∏µ',
                moderate: '‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á',
                unhealthy_sensitive: '‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á',
                unhealthy: '‡πÑ‡∏°‡πà‡∏î‡∏µ'
            }
            text += `\n‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: ${levels[s.aqi_level] || s.aqi_level}`
        }

        return text
    }

    return '‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß'
}
